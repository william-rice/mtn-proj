{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine Routes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merges the CSV route data with the JSON route data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in the CSV data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "scraped = pd.read_csv(\"scraped.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in the JSON data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to create a pandas dataframe from the `\"routes\"` entry in the JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_to_df(json_file):\n",
    "    json_dict = json.load(json_file)\n",
    "    just_routes = json_dict[\"routes\"]\n",
    "    return pd.DataFrame(just_routes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go through every JSON file in the folder, unioning their route data into one dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"json-routes\"\n",
    "requested = []\n",
    "for file in os.scandir(directory):\n",
    "    with open(file.path, \"r\") as json_file:\n",
    "        if len(requested):\n",
    "            requested = pd.concat([requested, json_to_df(json_file)])\n",
    "        else:\n",
    "            requested = json_to_df(json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge the two datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lot of the data is overlapping, but there are a few features the API-pulled data has that the scraped data doesn't and vice-versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " scraped:\n",
      "\n",
      " Index(['Unnamed: 0', 'Route', 'Location', 'URL', 'Avg Stars', 'Your Stars',\n",
      "       'Route Type', 'Rating', 'Pitches', 'Length', 'Area Latitude',\n",
      "       'Area Longitude'],\n",
      "      dtype='object') \n",
      "\n",
      " requested:\n",
      "\n",
      " Index(['id', 'name', 'type', 'rating', 'stars', 'starVotes', 'pitches',\n",
      "       'location', 'url', 'imgSqSmall', 'imgSmall', 'imgSmallMed', 'imgMedium',\n",
      "       'longitude', 'latitude'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\" scraped:\\n\\n\", scraped.columns, \"\\n\\n\", \"requested:\\n\\n\", requested.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specifically, the **scraped** data has the vertical *length* of the route (in feet), the *rating* I've personally given routes I've climbed, and the \"*Area*\" *lat/lon* instead of the *route lat/lon*. \n",
    "\n",
    "From a quick inspection, the lat/lon values are the same, if truncated to fewer decimal places in the scraped data.\n",
    "\n",
    "The **requested** data, on the other hand, has a *starVotes* column (a nice proxy for traffic) and the *image* links."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before merging, I want to check for discrepancies between the two datasets. I'll start by adding a *route_id* column to the scraped dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_id = lambda entry: int(re.search(\"\\d{9}\", entry).group())\n",
    "scraped[\"id\"] = scraped[\"URL\"].apply(get_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"indices\" for both dataframes are not unique, so I'll use the route ID as the index instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scraped.index = scraped[\"id\"]\n",
    "requested.index = requested[\"id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can order them by this new index and start comparing various columns' values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scraped_sorted = scraped.sort_index()\n",
    "requested_sorted = requested.sort_index()\n",
    "all(scraped_sorted.index == requested_sorted.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above assures that all route_ids match up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, I'm going to define a little function that checks whether or not all values of features that are shared by both datasets match one another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_same(scraped_col, requested_col):\n",
    "    same = all(scraped_sorted[scraped_col] == requested_sorted[requested_col])\n",
    "    if same:\n",
    "        msg = \"are the same\"\n",
    "    else:\n",
    "        msg = \"don't match\"\n",
    "    return \"{} and {} {}\\n\".format(scraped_col, requested_col, msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Route and name are the same\n",
      "\n",
      "Location and location don't match\n",
      "\n",
      "URL and url are the same\n",
      "\n",
      "Avg Stars and stars don't match\n",
      "\n",
      "Route Type and type are the same\n",
      "\n",
      "Rating and rating are the same\n",
      "\n",
      "Pitches and pitches don't match\n",
      "\n",
      "Area Latitude and latitude don't match\n",
      "\n",
      "Area Longitude and longitude don't match\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scraped_cols = [\"Route\", \"Location\", \"URL\", \"Avg Stars\", \"Route Type\", \"Rating\", \"Pitches\", \"Area Latitude\", \"Area Longitude\"]\n",
    "requested_cols = [\"name\", \"location\", \"url\", \"stars\", \"type\", \"rating\", \"pitches\", \"latitude\", \"longitude\"]\n",
    "\n",
    "for i in range(len(scraped_cols)):\n",
    "    print(check_same(scraped_cols[i], requested_cols[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the ones that match, we'll just drop the column with the less-descriptive name. \n",
    "As for the non-matching items, let's see what's different about each of these."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Location**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id\n",
      "105888384    The Dihedrals > Foster Falls > Tennessee\n",
      "Name: Location, dtype: object id\n",
      "105888384    [Tennessee, Foster Falls, The Dihedrals]\n",
      "Name: location, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(scraped_sorted[\"Location\"].head(1), requested_sorted[\"location\"].head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because it's really just the formatting, I'll discard the first and keep the second, more convenient version."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stars**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id\n",
      "105888384    2.8\n",
      "105888407    2.6\n",
      "105892528    2.2\n",
      "Name: Avg Stars, dtype: float64 id\n",
      "105888384    3.8\n",
      "105888407    3.6\n",
      "105892528    3.2\n",
      "Name: stars, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(scraped_sorted[\"Avg Stars\"].head(3), requested_sorted[\"stars\"].head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These all differ by one. The API usage page explains that the former rating corresponds to the star rating a user might select on the app (ranges 1-4, inclusive) while the latter rating is adjusted to range 1-5, inclusive.\n",
    "\n",
    "It appears, however, that NA values have been imputed as -1 in the scraped dataset and as 0 in the requested dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>type</th>\n",
       "      <th>rating</th>\n",
       "      <th>stars</th>\n",
       "      <th>starVotes</th>\n",
       "      <th>pitches</th>\n",
       "      <th>location</th>\n",
       "      <th>url</th>\n",
       "      <th>imgSqSmall</th>\n",
       "      <th>imgSmall</th>\n",
       "      <th>imgSmallMed</th>\n",
       "      <th>imgMedium</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>111607012</th>\n",
       "      <td>111607012</td>\n",
       "      <td>The Peanut</td>\n",
       "      <td>Sport</td>\n",
       "      <td>5.12c</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[Alabama, Sand Rock, The Islands]</td>\n",
       "      <td>https://www.mountainproject.com/route/11160701...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>-85.8193</td>\n",
       "      <td>34.1792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111607023</th>\n",
       "      <td>111607023</td>\n",
       "      <td>Little Jerk</td>\n",
       "      <td>Trad</td>\n",
       "      <td>5.11c/d</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[Alabama, Sand Rock, The Islands]</td>\n",
       "      <td>https://www.mountainproject.com/route/11160702...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>-85.8193</td>\n",
       "      <td>34.1792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112293128</th>\n",
       "      <td>112293128</td>\n",
       "      <td>Feet don't fail me now</td>\n",
       "      <td>Sport</td>\n",
       "      <td>5.11a/b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[Tennessee, Foster Falls, Music City/The 5.9 A...</td>\n",
       "      <td>https://www.mountainproject.com/route/11229312...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>-85.7010</td>\n",
       "      <td>35.1869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113973514</th>\n",
       "      <td>113973514</td>\n",
       "      <td>Katana</td>\n",
       "      <td>Sport</td>\n",
       "      <td>5.12a</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[Tennessee, Foster Falls, Music City/The 5.9 A...</td>\n",
       "      <td>https://www.mountainproject.com/route/11397351...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>-85.7010</td>\n",
       "      <td>35.1869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117964031</th>\n",
       "      <td>117964031</td>\n",
       "      <td>Lee Trevino</td>\n",
       "      <td>Sport</td>\n",
       "      <td>5.11c</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[Alabama, Little River Canyon, Lizard Wall]</td>\n",
       "      <td>https://www.mountainproject.com/route/11796403...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>-85.6702</td>\n",
       "      <td>34.3588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id                    name   type   rating  stars  \\\n",
       "id                                                                    \n",
       "111607012  111607012              The Peanut  Sport    5.12c    0.0   \n",
       "111607023  111607023             Little Jerk   Trad  5.11c/d    0.0   \n",
       "112293128  112293128  Feet don't fail me now  Sport  5.11a/b    0.0   \n",
       "113973514  113973514                  Katana  Sport    5.12a    0.0   \n",
       "117964031  117964031             Lee Trevino  Sport    5.11c    0.0   \n",
       "\n",
       "           starVotes pitches  \\\n",
       "id                             \n",
       "111607012          0       1   \n",
       "111607023          0       1   \n",
       "112293128          0       1   \n",
       "113973514          0       1   \n",
       "117964031          0       1   \n",
       "\n",
       "                                                    location  \\\n",
       "id                                                             \n",
       "111607012                  [Alabama, Sand Rock, The Islands]   \n",
       "111607023                  [Alabama, Sand Rock, The Islands]   \n",
       "112293128  [Tennessee, Foster Falls, Music City/The 5.9 A...   \n",
       "113973514  [Tennessee, Foster Falls, Music City/The 5.9 A...   \n",
       "117964031        [Alabama, Little River Canyon, Lizard Wall]   \n",
       "\n",
       "                                                         url imgSqSmall  \\\n",
       "id                                                                        \n",
       "111607012  https://www.mountainproject.com/route/11160701...              \n",
       "111607023  https://www.mountainproject.com/route/11160702...              \n",
       "112293128  https://www.mountainproject.com/route/11229312...              \n",
       "113973514  https://www.mountainproject.com/route/11397351...              \n",
       "117964031  https://www.mountainproject.com/route/11796403...              \n",
       "\n",
       "          imgSmall imgSmallMed imgMedium  longitude  latitude  \n",
       "id                                                             \n",
       "111607012                                  -85.8193   34.1792  \n",
       "111607023                                  -85.8193   34.1792  \n",
       "112293128                                  -85.7010   35.1869  \n",
       "113973514                                  -85.7010   35.1869  \n",
       "117964031                                  -85.6702   34.3588  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requested_sorted[requested_sorted[\"stars\"] == 0] # Only where starVotes also equals zero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hate that. I'm going to just keep the *Avg Stars* version in the range from 1-4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pitches**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a route has no pitch information in the scraped dataset, its default is 1. In the requested dataset, its default is an empty string \"\". The first is going to be far more reasonable as multi-pitch routes will probably be more established and well-documented on the site."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Longitude/Latitude**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id\n",
      "105888384   -85.68004\n",
      "105888407   -85.68366\n",
      "105892528   -85.68247\n",
      "105892533   -85.67854\n",
      "105892538   -85.68420\n",
      "Name: Area Longitude, dtype: float64 id\n",
      "105888384   -85.6800\n",
      "105888407   -85.6837\n",
      "105892528   -85.6825\n",
      "105892533   -85.6785\n",
      "105892538   -85.6842\n",
      "Name: longitude, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(scraped_sorted[\"Area Longitude\"].head(), requested_sorted[\"longitude\"].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the values have just been rounded in the API dataset. So I'll keep the extra decimal place and stick with the scraped version."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In summary, I'll merge the datasets on their indices and drop the following columns:\n",
    "Route, Location, URL, stars, type, Rating, pitches, latitude, longitude.\n",
    "\n",
    "I'll also drop the obselete index titled \"unnamed: 0\" and the redundant \"id\" columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Avg Stars', 'Your Stars', 'Route Type', 'Pitches', 'Length',\n",
       "       'Area Latitude', 'Area Longitude', 'name', 'rating', 'starVotes',\n",
       "       'location', 'url', 'imgSqSmall', 'imgSmall', 'imgSmallMed',\n",
       "       'imgMedium'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged = pd.concat([scraped_sorted, requested_sorted], axis=1)\n",
    "for col in [\"Route\", \"Location\", \"URL\", \"stars\", \"type\", \"Rating\", \"pitches\", \"latitude\", \"longitude\", \"id\", \"Unnamed: 0\" ]:\n",
    "    merged.drop(col, axis=1, inplace=True)\n",
    "merged.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"merged.csv\", \"w\") as outfile:\n",
    "    merged.to_csv(outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I'll run some exploratory analyses on this combined dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
